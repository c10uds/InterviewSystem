# -*- coding: utf-8 -*-
"""
å·¥å…·å‡½æ•°
åŒ…å«å„ç§è¾…åŠ©å‡½æ•°å’Œå·¥å…·ç±»
"""

import os
import logging
import subprocess
import tempfile
import requests
import jwt
from functools import wraps
from flask import session, redirect, url_for, request, jsonify

from config import AI_BASE_URL, UPLOAD_FOLDER, JWT_SECRET, JWT_ALGORITHM
from llm_api import chat_manager, ask_llm_with_http

logger = logging.getLogger(__name__)

def login_required(f):
    """ç™»å½•éªŒè¯è£…é¥°å™¨"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = request.headers.get('Authorization')
        if not token:
            return jsonify({"error": "è¯·å…ˆç™»å½•"}), 401
        try:
            payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
            request.user = payload
        except Exception:
            return jsonify({"error": "tokenæ— æ•ˆæˆ–å·²è¿‡æœŸ"}), 401
        return f(*args, **kwargs)
    return decorated

def check_database_connection():
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸"""
    try:
        from models import db
        from app import app
        with app.app_context():
            with db.engine.connect() as conn:
                conn.execute(db.text('SELECT 1'))
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

def validate_models():
    """éªŒè¯æ•°æ®åº“æ¨¡å‹æ˜¯å¦æ­£ç¡®"""
    try:
        from models import db
        from app import app
        with app.app_context():
            with db.engine.connect() as conn:
                # æ£€æŸ¥Userè¡¨æ˜¯å¦å­˜åœ¨
                result = conn.execute(db.text("""
                    SELECT COUNT(*) as count 
                    FROM information_schema.tables 
                    WHERE table_schema = DATABASE() 
                    AND table_name = 'user'
                """))
                user_table_exists = result.fetchone()[0] > 0
                
                if not user_table_exists:
                    print("âŒ Userè¡¨ä¸å­˜åœ¨ï¼Œè¯·è¿è¡Œæ•°æ®åº“è¿ç§»")
                    return False
                
                # æ£€æŸ¥å¿…è¦çš„å­—æ®µæ˜¯å¦å­˜åœ¨
                result = conn.execute(db.text("""
                    SELECT COLUMN_NAME 
                    FROM information_schema.COLUMNS 
                    WHERE TABLE_SCHEMA = DATABASE() 
                    AND TABLE_NAME = 'user'
                """))
                columns = [row[0] for row in result.fetchall()]
                
                required_columns = ['id', 'email', 'password_hash', 'name', 'phone', 'school', 'grade', 'target_position', 'is_admin', 'avatar', 'resume_content', 'resume_filename', 'resume_upload_time']
                missing_columns = [col for col in required_columns if col not in columns]
                
                if missing_columns:
                    print(f"âŒ Userè¡¨ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_columns}")
                    print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ•°æ®åº“è¿ç§»:")
                    print("  flask db upgrade")
                    return False
                
                # æ£€æŸ¥InterviewRecordè¡¨æ˜¯å¦å­˜åœ¨
                result = conn.execute(db.text("""
                    SELECT COUNT(*) as count 
                    FROM information_schema.tables 
                    WHERE table_schema = DATABASE() 
                    AND table_name = 'interview_record'
                """))
                record_table_exists = result.fetchone()[0] > 0
            
            if not record_table_exists:
                print("âŒ InterviewRecordè¡¨ä¸å­˜åœ¨ï¼Œè¯·è¿è¡Œæ•°æ®åº“è¿ç§»")
                return False
            
            print("âœ… æ•°æ®åº“æ¨¡å‹éªŒè¯é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False

def startup_checks():
    """åº”ç”¨å¯åŠ¨æ—¶çš„æ£€æŸ¥"""
    print("ğŸ” å¼€å§‹å¯åŠ¨æ£€æŸ¥...")
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if not check_database_connection():
        print("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®åº“é…ç½®å’Œè¿æ¥")
        return False
    
    # æ£€æŸ¥æ•°æ®åº“æ¨¡å‹
    if not validate_models():
        print("ğŸ’¡ è¯·è¿è¡Œæ•°æ®åº“è¿ç§»")
        return False
    
    print("âœ… å¯åŠ¨æ£€æŸ¥å®Œæˆ")
    return True

class CppAISDK:
    """AIæœåŠ¡SDK"""
    def __init__(self, base_url):
        self.base_url = base_url

    def ask_llm(self, prompt, model="spark", chat_id=None):
        """å¤§æ¨¡å‹é—®ç­”ï¼Œä¼˜å…ˆä½¿ç”¨HTTP APIï¼Œå¤±è´¥æ—¶å›é€€åˆ°åŸæœ‰API"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨HTTP API
            from config import SPARK_API_KEY
            if SPARK_API_KEY != 'XXXXXXXXXXXXXXXXXXXXXXXX':
                logger.info(f"[ask_llm] ä½¿ç”¨HTTP APIè°ƒç”¨å¤§æ¨¡å‹: {prompt[:50]}...")
                
                # æ„å»ºæ¶ˆæ¯å†å²
                if chat_id:
                    # è·å–å¯¹è¯å†å²
                    messages = chat_manager.get_messages(chat_id)
                    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
                    chat_manager.add_message(chat_id, "user", prompt)
                    messages = chat_manager.get_messages(chat_id)
                else:
                    # å•è½®å¯¹è¯
                    messages = [{"role": "user", "content": prompt}]
                
                # ä½¿ç”¨HTTP APIè°ƒç”¨
                http_result = ask_llm_with_http(messages)
                if http_result and http_result.get("success"):
                    logger.info(f"[ask_llm] HTTP APIè°ƒç”¨æˆåŠŸ")
                    answer = http_result.get("answer", "")
                    
                    # å¦‚æœæœ‰chat_idï¼Œä¿å­˜åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
                    if chat_id and answer:
                        chat_manager.add_message(chat_id, "assistant", answer)
                    
                    return answer
                else:
                    logger.warning(f"[ask_llm] HTTP APIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰API: {http_result}")
            
            # å›é€€åˆ°åŸæœ‰API
            logger.info(f"[ask_llm] ä½¿ç”¨åŸæœ‰APIè°ƒç”¨: {prompt[:50]}...")
            data = {
                "question": prompt,
                "model": model
            }
            if chat_id:
                data["chat_id"] = chat_id
            logger.info(f"[ask_llm] è¯·æ±‚: {data}")
            
            res = requests.post(f"{self.base_url}/api/llm", data=data)
            res_json = res.json()
            logger.info(f"[ask_llm] å“åº”: {res_json}")
            if res_json.get("success"):
                return res_json.get("answer", "")
            else:
                return ""
        except Exception as e:
            logger.error(f"[ask_llm] å¼‚å¸¸: {e}")
            return ""

    def asr(self, audio_path, language="zh_cn"):
        """è¯­éŸ³è¯†åˆ«ï¼Œä¼˜å…ˆä½¿ç”¨å¤§æ¨¡å‹APIï¼Œå¤±è´¥æ—¶å›é€€åˆ°åŸæœ‰API"""
        import tempfile
        try:
            # è½¬ä¸ºç»å¯¹è·¯å¾„
            audio_path = os.path.abspath(audio_path)
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨å¤§æ¨¡å‹API
            from config import SPARK_APPID, SPARK_API_SECRET, SPARK_API_KEY
            if SPARK_APPID != 'XXXXXXXX' and SPARK_API_SECRET != 'XXXXXXXXXXXXXXXXXXXXXXXX' and SPARK_API_KEY != 'XXXXXXXXXXXXXXXXXXXXXXXX':
                logger.info(f"[asr] ä½¿ç”¨å¤§æ¨¡å‹APIè¯†åˆ«éŸ³é¢‘: {audio_path}")
                
                # ç¡®ä¿éŸ³é¢‘æ ¼å¼æ­£ç¡®ï¼ˆ16kå•å£°é“pcmï¼‰
                if not audio_path.endswith('.pcm'):
                    # åœ¨UPLOAD_FOLDERä¸‹åˆ›å»ºä¸´æ—¶pcmæ–‡ä»¶
                    base = os.path.splitext(os.path.basename(audio_path))[0]
                    pcm_path = os.path.abspath(os.path.join(UPLOAD_FOLDER, f"{base}_tmp.pcm"))
                    # ffmpegè½¬ç ä¸º16kå•å£°é“pcm
                    cmd = [
                        'ffmpeg', '-y', '-i', audio_path,
                        '-f', 's16le', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', pcm_path
                    ]
                    subprocess.run(cmd, check=True)
                else:
                    pcm_path = audio_path
                
                # ä½¿ç”¨å¤§æ¨¡å‹APIè¯†åˆ«
                from llm_api import asr_with_llm
                llm_result = asr_with_llm(pcm_path, language)
                if llm_result and llm_result.get("success"):
                    logger.info(f"[asr] å¤§æ¨¡å‹è¯†åˆ«æˆåŠŸ: {llm_result}")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if pcm_path != audio_path and os.path.exists(pcm_path):
                        logger.info(f"[asr] åˆ é™¤ä¸´æ—¶pcmæ–‡ä»¶: {pcm_path}")
                        os.remove(pcm_path)
                    return llm_result.get("text", "")
                else:
                    logger.warning(f"[asr] å¤§æ¨¡å‹è¯†åˆ«å¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰API: {llm_result}")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if pcm_path != audio_path and os.path.exists(pcm_path):
                        os.remove(pcm_path)
            
            # å›é€€åˆ°åŸæœ‰API
            logger.info(f"[asr] ä½¿ç”¨åŸæœ‰APIè¯†åˆ«éŸ³é¢‘: {audio_path}")
            # åªè¦ä¸æ˜¯pcmå°±è½¬ç 
            if not audio_path.endswith('.pcm'):
                # åœ¨UPLOAD_FOLDERä¸‹åˆ›å»ºä¸´æ—¶pcmæ–‡ä»¶
                base = os.path.splitext(os.path.basename(audio_path))[0]
                pcm_path = os.path.abspath(os.path.join(UPLOAD_FOLDER, f"{base}_tmp.pcm"))
                # ffmpegè½¬ç ä¸º16kå•å£°é“pcmï¼ˆå‡è®¾ASRæœåŠ¡éœ€è¦ï¼‰
                cmd = [
                    'ffmpeg', '-y', '-i', audio_path,
                    '-f', 's16le', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', pcm_path
                ]
                subprocess.run(cmd, check=True)
            else:
                pcm_path = audio_path
            with open(pcm_path, "rb") as f:
                files = {"audio": f}
                data = {"language": language}
                logger.info(f"[asr] è¯·æ±‚: æ–‡ä»¶={pcm_path}, data={data}")
                res = requests.post(f"{self.base_url}/api/asr", files=files, data=data)
            res_json = res.json()
            logger.info(f"[asr] å“åº”: {res_json}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if pcm_path != audio_path and os.path.exists(pcm_path):
                logger.info(f"[asr] åˆ é™¤ä¸´æ—¶pcmæ–‡ä»¶: {pcm_path}")
                os.remove(pcm_path)
            if res_json.get("success"):
                return res_json.get("text", "")
            else:
                return ""
        except Exception as e:
            logger.error(f"[asr] å¼‚å¸¸: {e}")
            return ""

    def tts(self, text, voice="xiaoyan", format="wav"):
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        data = {
            "text": text,
            "voice": voice,
            "format": format
        }
        logger.info(f"[tts] è¯·æ±‚: {data}")
        try:
            res = requests.post(f"{self.base_url}/api/tts", data=data)
            res_json = res.json()
            logger.info(f"[tts] å“åº”: {res_json}")
            if res_json.get("success"):
                return res_json.get("audio_url", "")
            else:
                return ""
        except Exception as e:
            logger.error(f"[tts] å¼‚å¸¸: {e}")
            return ""

    def analyze_image(self, image_path, analysis_type="interview_scene", detect_faces=True, analyze_emotion=True, analyze_micro_expression=False):
        """åˆ†æå›¾ç‰‡ï¼Œä½¿ç”¨å®˜æ–¹å¤§æ¨¡å‹APIè¿›è¡Œå¾®è¡¨æƒ…åˆ†æ"""
        try:
            # ä½¿ç”¨å®˜æ–¹å¤§æ¨¡å‹API
            from config import SPARK_APPID, SPARK_API_SECRET, SPARK_API_KEY
            if SPARK_APPID != 'XXXXXXXX' and SPARK_API_SECRET != 'XXXXXXXXXXXXXXXXXXXXXXXX' and SPARK_API_KEY != 'XXXXXXXXXXXXXXXXXXXXXXXX':
                logger.info(f"[analyze_image] ä½¿ç”¨å®˜æ–¹å¤§æ¨¡å‹APIåˆ†æå›¾ç‰‡: {image_path}")
                
                # ä½¿ç”¨è®¯é£äººè„¸ç‰¹å¾åˆ†æAPI
                from llm_api import analyze_image_with_face_expression_api
                llm_result = analyze_image_with_face_expression_api(image_path)
                if llm_result.get("success"):
                    logger.info(f"[analyze_image] å¤§æ¨¡å‹åˆ†ææˆåŠŸ: {llm_result}")
                    
                    # è§£æåˆ†æç»“æœï¼Œæå–å¾®è¡¨æƒ…ä¿¡æ¯
                    analysis_text = llm_result.get("analysis", "")
                    
                    # å°è¯•è§£æJSONæ ¼å¼çš„åˆ†æç»“æœ
                    try:
                        import json
                        analysis_data = json.loads(analysis_text)
                        emotions = analysis_data.get('emotions', {})
                        micro_expressions = analysis_data.get('micro_expressions', {})
                        confidence = analysis_data.get('confidence', 0.8)
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
                        emotions = {"primary_emotion": "analyzed_by_llm", "confidence": 0.8}
                        micro_expressions = {"detected": "analyzed_by_llm", "confidence": 0.8}
                        confidence = 0.8
                    
                    return {
                        "success": True,
                        "analysis": analysis_text,
                        "source": "llm",
                        "emotions": emotions,
                        "micro_expressions": micro_expressions,
                        "confidence": confidence,
                        "analysis_type": "interview_micro_expression"
                    }
                else:
                    logger.warning(f"[analyze_image] å¤§æ¨¡å‹åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰API: {llm_result}")
            
            # å›é€€åˆ°åŸæœ‰API
            logger.info(f"[analyze_image] ä½¿ç”¨åŸæœ‰APIåˆ†æå›¾ç‰‡: {image_path}")
            with open(image_path, "rb") as f:
                files = {"image": f}
                data = {
                    "analysis_type": analysis_type,
                    "detect_faces": str(detect_faces).lower(),
                    "analyze_emotion": str(analyze_emotion).lower(),
                    "analyze_micro_expression": str(analyze_micro_expression).lower()
                }
                logger.info(f"[analyze_image] è¯·æ±‚: æ–‡ä»¶={image_path}, data={data}")
                res = requests.post(f"{self.base_url}/api/image", files=files, data=data)
            res_json = res.json()
            logger.info(f"[analyze_image] å“åº”: {res_json}")
            if res_json.get("success"):
                return res_json
            else:
                return {}
        except Exception as e:
            logger.error(f"[analyze_image] å¼‚å¸¸: {e}")
            return {}

# å…¨å±€AI SDKå®ä¾‹ - å·²æ›¿æ¢ä¸ºWebSocketè°ƒç”¨
# cpp_sdk = CppAISDK(AI_BASE_URL)

def next_question(position, questions, answers, chat_id=None):
    """ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜"""
    logger.info(f"[next_question] position={position}, questions={questions}, answers={answers}, chat_id={chat_id}")
    
    # ä½¿ç”¨WebSocketè°ƒç”¨å¤§æ¨¡å‹
    from llm_api import ask_llm_with_http
    
    if not questions:
        prompt = f"ä½ æ˜¯{position}å²—ä½çš„é¢è¯•å®˜ï¼Œè¯·ç»™å‡ºç¬¬ä¸€ä¸ªé¢è¯•é—®é¢˜ã€‚è¯·åªç”¨ä¸€å¥è¯è¿”å›é—®é¢˜å†…å®¹ï¼Œä¸è¦æœ‰å¤šä½™è§£é‡Šã€‚"
        messages = [{"role": "user", "content": prompt}]
        result = ask_llm_with_http(messages)
        if result and result.get("success"):
            q = result.get("answer", "")
            logger.info(f"[next_question] AIåŸå§‹è¿”å›: {q}")
            return q if isinstance(q, str) else str(q)
        else:
            logger.error(f"[next_question] å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {result}")
            return "è¯·ä»‹ç»ä¸€ä¸‹ä½ çš„æŠ€æœ¯èƒŒæ™¯å’Œç»éªŒã€‚"
    else:
        prompt = (
            f"ä½ æ˜¯{position}å²—ä½çš„é¢è¯•å®˜ã€‚å·²é—®è¿‡å¦‚ä¸‹é—®é¢˜åŠå›ç­”ï¼š\n" +
            "".join([
                f"Q{j+1}:{questions[j]}\nA{j+1}:{answers[j]}\n" for j in range(len(answers))
            ]) +
            "è¯·æ ¹æ®åº”è˜è€…çš„æœ€æ–°å›ç­”ï¼Œæå‡ºä¸‹ä¸€ä¸ªæ›´æœ‰é’ˆå¯¹æ€§çš„é—®é¢˜ã€‚è¯·åªç”¨ä¸€å¥è¯è¿”å›é—®é¢˜å†…å®¹ï¼Œä¸è¦æœ‰å¤šä½™è§£é‡Šã€‚"
        )
        messages = [{"role": "user", "content": prompt}]
        result = ask_llm_with_http(messages)
        if result and result.get("success"):
            next_q = result.get("answer", "")
            logger.info(f"[next_question] AIåŸå§‹è¿”å›: {next_q}")
            return next_q if isinstance(next_q, str) else str(next_q)
        else:
            logger.error(f"[next_question] å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {result}")
            return "è¯·è¯¦ç»†è¯´æ˜ä½ åœ¨é¡¹ç›®ä¸­çš„å…·ä½“è´¡çŒ®ã€‚"

def evaluate_interview(position, questions, answers, chat_id=None):
    """è¯„ä¼°é¢è¯•ç»“æœ"""
    logger.info(f"[evaluate_interview] position={position}, questions={questions}, answers={answers}, chat_id={chat_id}")
    
    # ä½¿ç”¨WebSocketè°ƒç”¨å¤§æ¨¡å‹
    from llm_api import ask_llm_with_http
    
    eval_prompt = (
        "è¯·æ ¹æ®ä»¥ä¸‹é¢è¯•é—®é¢˜å’Œå›ç­”ï¼Œä»ä¸“ä¸šçŸ¥è¯†æ°´å¹³ã€æŠ€èƒ½åŒ¹é…åº¦ã€è¯­è¨€è¡¨è¾¾èƒ½åŠ›ã€é€»è¾‘æ€ç»´èƒ½åŠ›ã€åˆ›æ–°èƒ½åŠ›ã€åº”å˜æŠ—å‹èƒ½åŠ›å…­ä¸ªç»´åº¦ï¼Œé‡åŒ–è¯„æµ‹å¹¶ç»™å‡ºå»ºè®®ï¼š\n"
    )
    for i, (q, a) in enumerate(zip(questions, answers)):
        eval_prompt += f"Q{i+1}: {q}\nA{i+1}: {a}\n"
    eval_prompt += (
        "è¯·ä»¥å¦‚ä¸‹æ ‡å‡†JSONæ ¼å¼è¿”å›ï¼š\n"
        "{\n"
        "  \"abilities\": {\n"
        "    \"ä¸“ä¸šçŸ¥è¯†æ°´å¹³\": 0-100,\n"
        "    \"æŠ€èƒ½åŒ¹é…åº¦\": 0-100,\n"
        "    \"è¯­è¨€è¡¨è¾¾èƒ½åŠ›\": 0-100,\n"
        "    \"é€»è¾‘æ€ç»´èƒ½åŠ›\": 0-100,\n"
        "    \"åˆ›æ–°èƒ½åŠ›\": 0-100,\n"
        "    \"åº”å˜æŠ—å‹èƒ½åŠ›\": 0-100\n"
        "  },\n"
        "  \"suggestions\": [\"å»ºè®®1\", \"å»ºè®®2\"]\n"
        "}\n"
        "ä¸è¦æœ‰å¤šä½™è§£é‡Šã€‚"
    )
    
    messages = [{"role": "user", "content": eval_prompt}]
    result = ask_llm_with_http(messages)
    if result and result.get("success"):
        eval_result = result.get("answer", "")
        logger.info(f"[evaluate_interview] AIåŸå§‹è¯„æµ‹ç»“æœ: {eval_result}")
        return eval_result
    else:
        logger.error(f"[evaluate_interview] å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {result}")
        return "{\"abilities\": {\"ä¸“ä¸šçŸ¥è¯†æ°´å¹³\": 70, \"æŠ€èƒ½åŒ¹é…åº¦\": 75, \"è¯­è¨€è¡¨è¾¾èƒ½åŠ›\": 80, \"é€»è¾‘æ€ç»´èƒ½åŠ›\": 75, \"åˆ›æ–°èƒ½åŠ›\": 70, \"åº”å˜æŠ—å‹èƒ½åŠ›\": 75}, \"suggestions\": [\"å»ºè®®åŠ å¼ºä¸“ä¸šæŠ€èƒ½å­¦ä¹ \", \"å»ºè®®æå‡æ²Ÿé€šè¡¨è¾¾èƒ½åŠ›\"]}"

def evaluate_interview_with_images(position, questions, answers, image_analyses, chat_id=None):
    """ç»“åˆå¾®è¡¨æƒ…åˆ†æçš„é¢è¯•è¯„ä¼°"""
    logger.info(f"[evaluate_interview_with_images] position={position}, questions={questions}, answers={answers}, image_analyses={image_analyses}, chat_id={chat_id}")
    
    # æ„å»ºåŒ…å«å¾®è¡¨æƒ…åˆ†æçš„è¯„æµ‹æç¤º
    eval_prompt = (
        "è¯·æ ¹æ®ä»¥ä¸‹é¢è¯•é—®é¢˜å’Œå›ç­”ï¼Œä»¥åŠé¢è¯•è¿‡ç¨‹ä¸­çš„å¾®è¡¨æƒ…åˆ†æç»“æœï¼Œä»ä¸“ä¸šçŸ¥è¯†æ°´å¹³ã€æŠ€èƒ½åŒ¹é…åº¦ã€è¯­è¨€è¡¨è¾¾èƒ½åŠ›ã€é€»è¾‘æ€ç»´èƒ½åŠ›ã€åˆ›æ–°èƒ½åŠ›ã€åº”å˜æŠ—å‹èƒ½åŠ›ã€æƒ…ç»ªç¨³å®šæ€§ä¸ƒä¸ªç»´åº¦ï¼Œé‡åŒ–è¯„æµ‹å¹¶ç»™å‡ºå»ºè®®ï¼š\n\n"
    )
    
    # æ·»åŠ é—®ç­”å†…å®¹å’Œå¾®è¡¨æƒ…åˆ†æ
    for i, (q, a) in enumerate(zip(questions, answers)):
        eval_prompt += f"Q{i+1}: {q}\nA{i+1}: {a}\n"
        
        # æ·»åŠ å¯¹åº”çš„å¾®è¡¨æƒ…åˆ†æç»“æœ
        if i < len(image_analyses) and image_analyses[i]:
            eval_prompt += f"ç¬¬{i+1}é¢˜ç­”é¢˜æ—¶çš„å¾®è¡¨æƒ…åˆ†æï¼š\n"
            for j, analysis in enumerate(image_analyses[i]):
                if analysis and isinstance(analysis, dict):
                    analysis_text = analysis.get('analysis', '')
                    emotions = analysis.get('emotions', {})
                    micro_expressions = analysis.get('micro_expressions', {})
                    confidence = analysis.get('confidence', 0)
                    
                    eval_prompt += f"  å›¾ç‰‡{j+1}åˆ†æç»“æœ: {analysis_text}\n"
                    if emotions:
                        eval_prompt += f"    ä¸»è¦æƒ…ç»ª: {emotions}\n"
                    if micro_expressions:
                        eval_prompt += f"    å¾®è¡¨æƒ…: {micro_expressions}\n"
                    eval_prompt += f"    ç½®ä¿¡åº¦: {confidence}\n"
            eval_prompt += "\n"
    
    eval_prompt += (
        "è¯·ç»¼åˆè€ƒè™‘å›ç­”å†…å®¹å’Œå¾®è¡¨æƒ…åˆ†æç»“æœï¼Œä»¥å¦‚ä¸‹æ ‡å‡†JSONæ ¼å¼è¿”å›è¯„ä¼°ï¼š\n"
        "{\n"
        "  \"abilities\": {\n"
        "    \"ä¸“ä¸šçŸ¥è¯†æ°´å¹³\": 0-100,\n"
        "    \"æŠ€èƒ½åŒ¹é…åº¦\": 0-100,\n"
        "    \"è¯­è¨€è¡¨è¾¾èƒ½åŠ›\": 0-100,\n"
        "    \"é€»è¾‘æ€ç»´èƒ½åŠ›\": 0-100,\n"
        "    \"åˆ›æ–°èƒ½åŠ›\": 0-100,\n"
        "    \"åº”å˜æŠ—å‹èƒ½åŠ›\": 0-100,\n"
        "    \"æƒ…ç»ªç¨³å®šæ€§\": 0-100\n"
        "  },\n"
        "  \"suggestions\": [\"å»ºè®®1\", \"å»ºè®®2\", \"å»ºè®®3\"],\n"
        "  \"emotion_analysis\": {\n"
        "    \"overall_emotion\": \"æ•´ä½“æƒ…ç»ªçŠ¶æ€\",\n"
        "    \"confidence_level\": \"æƒ…ç»ªç¨³å®šæ€§è¯„åˆ†\",\n"
        "    \"interview_performance\": \"é¢è¯•è¡¨ç°è¯„ä¼°\"\n"
        "  },\n"
        "  \"micro_expression_impact\": \"å¾®è¡¨æƒ…å¯¹é¢è¯•è¡¨ç°çš„å½±å“åˆ†æ\"\n"
        "}\n"
        "è¯·ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œä¸è¦æœ‰å¤šä½™è§£é‡Šã€‚"
    )
    
    # ä½¿ç”¨WebSocketè°ƒç”¨å¤§æ¨¡å‹
    from llm_api import ask_llm_with_http
    
    messages = [{"role": "user", "content": eval_prompt}]
    result = ask_llm_with_http(messages)
    if result and result.get("success"):
        eval_result = result.get("answer", "")
        logger.info(f"[evaluate_interview_with_images] AIåŸå§‹è¯„æµ‹ç»“æœ: {eval_result}")
        return eval_result
    else:
        logger.error(f"[evaluate_interview_with_images] å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {result}")
        return "{\"abilities\": {\"ä¸“ä¸šçŸ¥è¯†æ°´å¹³\": 70, \"æŠ€èƒ½åŒ¹é…åº¦\": 75, \"è¯­è¨€è¡¨è¾¾èƒ½åŠ›\": 80, \"é€»è¾‘æ€ç»´èƒ½åŠ›\": 75, \"åˆ›æ–°èƒ½åŠ›\": 70, \"åº”å˜æŠ—å‹èƒ½åŠ›\": 75, \"æƒ…ç»ªç¨³å®šæ€§\": 80}, \"suggestions\": [\"å»ºè®®åŠ å¼ºä¸“ä¸šæŠ€èƒ½å­¦ä¹ \", \"å»ºè®®æå‡æ²Ÿé€šè¡¨è¾¾èƒ½åŠ›\", \"å»ºè®®ä¿æŒæƒ…ç»ªç¨³å®š\"], \"emotion_analysis\": {\"overall_emotion\": \"æ•´ä½“æƒ…ç»ªç¨³å®š\", \"confidence_level\": \"æƒ…ç»ªç¨³å®šæ€§è‰¯å¥½\", \"interview_performance\": \"é¢è¯•è¡¨ç°è‰¯å¥½\"}, \"micro_expression_impact\": \"å¾®è¡¨æƒ…åˆ†ææ˜¾ç¤ºé¢è¯•è€…æƒ…ç»ªç¨³å®šï¼Œæœ‰åŠ©äºé¢è¯•è¡¨ç°\"}" 